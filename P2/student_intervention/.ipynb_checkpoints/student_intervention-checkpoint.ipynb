{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Project 2: Supervised Learning\n",
    "### Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification vs Regression\n",
    "\n",
    "Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?\n",
    "\n",
    "As we want to predict weather a given student will pass or fail, given information about his life and habits, this\n",
    "indicates a classification problem with two classes, pass and fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Student data read successfully!\"\n",
    "# Note: The last column 'passed' is the target/label, all other are feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of students\n",
    "- Number of students who passed\n",
    "- Number of students who failed\n",
    "- Graduation rate of the class (%)\n",
    "- Number of features\n",
    "\n",
    "_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute desired values - replace each '?' with an appropriate expression/function call\n",
    "\n",
    "n_students = student_data.shape[0]\n",
    "n_features = student_data.shape[1] - 1\n",
    "n_passed = sum([1 for y in student_data['passed'] if y == 'yes'])\n",
    "n_failed = sum([1 for n in student_data['passed'] if n == 'no'])\n",
    "grad_rate = 100.*n_passed/(n_passed + n_failed)\n",
    "\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Let's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\n",
    "**Note**: For this dataset, the last column (`'passed'`) is the target or label we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "Target column: passed\n",
      "\n",
      "Feature values:-\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(student_data.columns[:-1])  # all columns but last are features\n",
    "target_col = student_data.columns[-1]  # last column is the target/label\n",
    "print \"Feature column(s):-\\n{}\".format(feature_cols)\n",
    "print \"Target column: {}\".format(target_col)\n",
    "\n",
    "X_all = student_data[feature_cols]  # feature values for all students\n",
    "y_all = student_data[target_col]  # corresponding targets/labels\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48):-\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": [
    "# First, decide how many training vs test samples you want\n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = 300  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size = .24, random_state = 0)\n",
    "\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Choose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\n",
    "\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "- Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.\n",
    "\n",
    "Produce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\n",
    "\n",
    "Note: You need to produce 3 such tables - one for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "**Model consideration**  \n",
    "\n",
    "Before we manipulated it, the data was strongly categorical. Even age, though ordered, basically could be thought of as buckets between 15 and 22. So initially I thought that maybe the DecisionTree would be the most apt to deal with this problem. Even though we saw in the lectures that decision trees handle continuous data as well, the motivation for the algorithm presented in class, made me think that it would handle this \"categorical\" data well (even though we made it numeric). In class we had a boolean function with several weather related categories as input, and an output of play/no play tenis. Here we have data that is closely categorical, with a pass/no pass output. To get my bearings and not to impose any pre-judgement, I wanted to try most of the classifiers seen in class out of the box. I excluded neural net, since its recommended use requires the features to be scaled (one of the disadvantages of that algorithm). The result of this can be seen in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Return the classifier's training time\n",
    "def timeTraining(clf, X_train, y_train):\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    return (end - start)\n",
    "\n",
    "# Return the classifier's predictions and prediction time\n",
    "def predictAndTime(clf, features):\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    return y_pred, (end - start)\n",
    "\n",
    "# Return the f1 score for the target values and predictions\n",
    "def F1(target, prediction):\n",
    "    return f1_score(target.values, prediction, pos_label='yes')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training time</th>\n",
       "      <td>0.0035 s</td>\n",
       "      <td>0.0069 s</td>\n",
       "      <td>0.0009 s</td>\n",
       "      <td>0.1022 s</td>\n",
       "      <td>0.0007 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score training set</th>\n",
       "      <td>1</td>\n",
       "      <td>0.874614</td>\n",
       "      <td>0.799737</td>\n",
       "      <td>0.870058</td>\n",
       "      <td>0.889301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction time</th>\n",
       "      <td>0.0002 s</td>\n",
       "      <td>0.0007 s</td>\n",
       "      <td>0.0003 s</td>\n",
       "      <td>0.0053 s</td>\n",
       "      <td>0.0011 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score test set</th>\n",
       "      <td>0.702098</td>\n",
       "      <td>0.807571</td>\n",
       "      <td>0.767603</td>\n",
       "      <td>0.76675</td>\n",
       "      <td>0.780717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DecisionTreeClassifier           SVC    GaussianNB  \\\n",
       "Training time                       0.0035 s      0.0069 s      0.0009 s   \n",
       "F1 score training set                      1      0.874614      0.799737   \n",
       "Prediction time                     0.0002 s      0.0007 s      0.0003 s   \n",
       "F1 score test set                   0.702098      0.807571      0.767603   \n",
       "\n",
       "                      AdaBoostClassifier KNeighborsClassifier  \n",
       "Training time                   0.1022 s             0.0007 s  \n",
       "F1 score training set           0.870058             0.889301  \n",
       "Prediction time                 0.0053 s             0.0011 s  \n",
       "F1 score test set                0.76675             0.780717  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To get my bearings I wanted to try most of the classifiers seen in class out of the box.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#Adding Kfold validation to try out the Pro Tip from CodeReview2\n",
    "from sklearn.cross_validation import KFold  \n",
    "\n",
    "# Setting up KFold cross_validation object\n",
    "kf = KFold(X_train.shape[0], 10)\n",
    "\n",
    "# Array of classifiers\n",
    "clfs = [DecisionTreeClassifier(criterion = \"entropy\"),\n",
    "        SVC(C = 1.0, kernel=\"rbf\"),\n",
    "        GaussianNB(),\n",
    "        AdaBoostClassifier(),\n",
    "        KNeighborsClassifier(n_neighbors = 3)]\n",
    " \n",
    "#Gathering Table column and index labels\n",
    "classifier_names = [clf.__class__.__name__ for clf in clfs]\n",
    "benchmarks = [\"Training time\",  \"F1 score training set\",\"Prediction time\", \"F1 score test set\"]\n",
    "table = pd.DataFrame(columns = classifier_names, index = benchmarks)\n",
    "\n",
    "# Fit Classifiers and average the times and f1 scores resulting from KFold (10 folds)\n",
    "for clf in clfs: \n",
    "    classifier   = clf.__class__.__name__\n",
    "    t_test  = 0.0 \n",
    "    t_train = 0.0\n",
    "    F1_test = 0.0\n",
    "    F1_train =0.0\n",
    "    \n",
    "    #Averaging scores and seconds accross the folds\n",
    "    for tr_i ,t_i in kf:\n",
    "        #Train (k-1 buckets)\n",
    "        t_train += timeTraining(clf, X_train.iloc[tr_i], y_train.iloc[tr_i])\n",
    "        pred_train_set = predictAndTime(clf, X_train.iloc[tr_i])[0]\n",
    "        F1_train += F1(y_train.iloc[tr_i], pred_train_set)\n",
    "        #Test (kth bucket)\n",
    "        pred_test_set, t_t = predictAndTime(clf,X_train.iloc[t_i])\n",
    "        t_test += t_t\n",
    "        F1_test += F1(y_train.iloc[t_i], pred_test_set)\n",
    "        \n",
    "    #Filling table \n",
    "    table[classifier]['Training time']         = \"{:10.4f} s\".format(t_train/10)\n",
    "    table[classifier]['F1 score training set'] = F1_train/10\n",
    "    table[classifier]['Prediction time']       = \"{:10.4f} s\".format(t_test/10)\n",
    "    table[classifier]['F1 score test set']     = F1_test/10\n",
    "    \n",
    "from IPython.display import display, HTML  \n",
    "display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At CodeReview2 my reviewer reminded me of how Kfold cross validation can be used to get the maximum use of a small data set like the one here. After separating the data into a training set (size 300) and test set (size 95), I used Kfold cross-validation on the training set with 10 folds to have a basic handle on how the models were performing on average. It is clearer now how they differ in performance. The decision tree trails all others in its f1 test score, while scoring perfectly on the training set (which no other does) so it seems to be an over-fitter. This is a known possible problem with trees. The SVC tops all others with an average test f1 of 0.808. KNN doesn't trail far with 0.781. Naive Bayes and AdaBoost are pretty much tied with test f1's of 0.768 and 0.767 respectively. \n",
    "\n",
    "As to narrowing the field to 3 models, I will discount AdaBoostClassifier and GaussianNB. Though I did not find this explicitly stated in the documentation, from the above table, AdaBoost is clearly expensive to train as its average training time of 0.1022s is approximately 15 times slower than the next slowest time of 0.069s by SVC. Since computational cost is a constraint, other algorithms may better serve this problem. GaussianNB was one of the fastest to be trained and had a decent average f1 test score. Two of Naive Bayes' advantages that are relevant to this problem are, its capacity to train on small amounts of data and its training speed. In this sense it is perfectly suited for the situation at hand. The main reason I passe on it, is the lack of tune-able parameters in sklearn's GaussianNB implementation. So I don't have a real chance of improving its performance from here, what I see now is what I get (I maybe wrong on this). \n",
    "\n",
    "As touched on in my previous comments decision tree is easy to conceptualize. It is also fast to use, as predicting data has logarithmic cost on number of  features (it had the fastest prediction time above too). A possible problem that I might encounter is its instability in generating a tree consistently upon data variation. Upon closer reading of section 1.6.4 of Sklearn's documentation, \"Nearest Neighbor Algorithms\", KNN as, I used it here, makes a choice of algorithm based on the data passed to fit(). The choice being between brute force, K-D tree, and Ball tree. This data set is too large for brute force (n = 300 >> 30) so we can consider KNN here as either K-D or Ball tree. Now, since the size of the feature space, is for computational purposes, D = 48 > 20 (after adding all the dummy classes) it is likely it is choosing Ball Tree. In any case its time complexity at prediction is O[Dlog(N)] which explains why its slower than the decision tree. Since the amount of student features is not likely to change much if KNN is put to practice in our scenario (suppose we choose it in the end for use of the school board), this can be consider a pro for this algorithm, since it is essentially logarithmic, just as the decision tree. Also from sklearn;  \n",
    "\n",
    "“Ball tree and KD tree query times can be greatly influenced by data structure. In general, sparser data with a smaller intrinsic dimensionality leads to faster query times.”  \n",
    "\n",
    "If I'm understanding correctly (may very well not be) since sparcity of the data set “refers to the degree to which the data fills the parameter space” ,  then it seems to me that the data set here is somewhat sparse. The reason I say this is because when we added the dummies, essentially we added a lot of zero components to each student “vector”. Since the student's mother, say, cannot be partially between being a Teacher and Healthcare worker, in regard to those categorical variables, there are regions in the feature space that are empty. Because no vectors will ever have components that are non-zero there. If this is indeed the case, then it would also be a pro for KNN. The advantages of SVC are that it is memory efficient because it only uses a subset of the training points in the decision function. This fits our computational cost constraint. It is also very customizable at the tuning phase (4 kernel options plus parameters). Since we are not concerned with probability estimates here, which SVC does expensively, it has little downsides. Next I try each of these models with varying training set sizes, from 50 students to 300 in increments of 50, for a total of 6 training set sizes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function makeTable\n",
    "def makeTable(clf, training_sizes, X_tr, X_t, y_tr, y_t):\n",
    "    \n",
    "    #Gathering column and row labels for the table\n",
    "    benchmarks = [\"Training time\",  \"F1 score training set\",\"Prediction time\", \"F1 score test set\"]\n",
    "    size_labels = [\"Training samples: {}\".format(s) for s in training_sizes]\n",
    "    table = pd.DataFrame(columns = benchmarks, index = size_labels)\n",
    "    \n",
    "    for i, size in enumerate(training_sizes):\n",
    "        #Use only the first \"size\" number of samples\n",
    "        X_train, X_test, y_train, y_test = [df.iloc[:size] for df in [X_tr, X_t, y_tr, y_t]]\n",
    "        \n",
    "        #Compute benchmarks\n",
    "        t_train    = timeTraining(clf, X_train, y_train)\n",
    "        pred_train_set = predictAndTime(clf, X_train)[0]\n",
    "        pred_test_set, t_test = predictAndTime(clf,X_test)  \n",
    "        \n",
    "        #fill table\n",
    "        table['Training time'][i]    = t_train\n",
    "        table['F1 score training set'][i] = F1(y_train, pred_train_set)\n",
    "        table['Prediction time'][i]  = t_test\n",
    "        table['F1 score test set'][i] = F1(y_test, pred_test_set)\n",
    "        \n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>F1 score training set</th>\n",
       "      <th>Prediction time</th>\n",
       "      <th>F1 score test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training samples: 50</th>\n",
       "      <td>0.00178289</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000478983</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 100</th>\n",
       "      <td>0.00202084</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000292063</td>\n",
       "      <td>0.713043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 150</th>\n",
       "      <td>0.0025692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00028491</td>\n",
       "      <td>0.68254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 200</th>\n",
       "      <td>0.00457883</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000495911</td>\n",
       "      <td>0.728682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 250</th>\n",
       "      <td>0.00521111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000490189</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 300</th>\n",
       "      <td>0.00376606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000236988</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\n",
       "Training samples: 50     0.00178289                     1     0.000478983   \n",
       "Training samples: 100    0.00202084                     1     0.000292063   \n",
       "Training samples: 150     0.0025692                     1      0.00028491   \n",
       "Training samples: 200    0.00457883                     1     0.000495911   \n",
       "Training samples: 250    0.00521111                     1     0.000490189   \n",
       "Training samples: 300    0.00376606                     1     0.000236988   \n",
       "\n",
       "                      F1 score test set  \n",
       "Training samples: 50           0.730159  \n",
       "Training samples: 100          0.713043  \n",
       "Training samples: 150           0.68254  \n",
       "Training samples: 200          0.728682  \n",
       "Training samples: 250          0.721311  \n",
       "Training samples: 300              0.75  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>F1 score training set</th>\n",
       "      <th>Prediction time</th>\n",
       "      <th>F1 score test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training samples: 50</th>\n",
       "      <td>0.00140691</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>0.000607014</td>\n",
       "      <td>0.738462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 100</th>\n",
       "      <td>0.00197101</td>\n",
       "      <td>0.85906</td>\n",
       "      <td>0.00135183</td>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 150</th>\n",
       "      <td>0.00450397</td>\n",
       "      <td>0.870813</td>\n",
       "      <td>0.00194883</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 200</th>\n",
       "      <td>0.0061152</td>\n",
       "      <td>0.869281</td>\n",
       "      <td>0.00191188</td>\n",
       "      <td>0.77551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 250</th>\n",
       "      <td>0.00635195</td>\n",
       "      <td>0.879177</td>\n",
       "      <td>0.00191903</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 300</th>\n",
       "      <td>0.00846219</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.00212193</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\n",
       "Training samples: 50     0.00140691               0.90625     0.000607014   \n",
       "Training samples: 100    0.00197101               0.85906      0.00135183   \n",
       "Training samples: 150    0.00450397              0.870813      0.00194883   \n",
       "Training samples: 200     0.0061152              0.869281      0.00191188   \n",
       "Training samples: 250    0.00635195              0.879177      0.00191903   \n",
       "Training samples: 300    0.00846219              0.869198      0.00212193   \n",
       "\n",
       "                      F1 score test set  \n",
       "Training samples: 50           0.738462  \n",
       "Training samples: 100          0.783784  \n",
       "Training samples: 150          0.771429  \n",
       "Training samples: 200           0.77551  \n",
       "Training samples: 250          0.758621  \n",
       "Training samples: 300          0.758621  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>F1 score training set</th>\n",
       "      <th>Prediction time</th>\n",
       "      <th>F1 score test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training samples: 50</th>\n",
       "      <td>0.000960112</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000761986</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 100</th>\n",
       "      <td>0.000619888</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.00151801</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 150</th>\n",
       "      <td>0.000834942</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.00256419</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 200</th>\n",
       "      <td>0.00111508</td>\n",
       "      <td>0.86121</td>\n",
       "      <td>0.00196004</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 250</th>\n",
       "      <td>0.000755072</td>\n",
       "      <td>0.889503</td>\n",
       "      <td>0.00311494</td>\n",
       "      <td>0.711111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 300</th>\n",
       "      <td>0.000849962</td>\n",
       "      <td>0.886878</td>\n",
       "      <td>0.00293112</td>\n",
       "      <td>0.721805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\n",
       "Training samples: 50    0.000960112                   0.8     0.000761986   \n",
       "Training samples: 100   0.000619888              0.823529      0.00151801   \n",
       "Training samples: 150   0.000834942              0.816327      0.00256419   \n",
       "Training samples: 200    0.00111508               0.86121      0.00196004   \n",
       "Training samples: 250   0.000755072              0.889503      0.00311494   \n",
       "Training samples: 300   0.000849962              0.886878      0.00293112   \n",
       "\n",
       "                      F1 score test set  \n",
       "Training samples: 50           0.761905  \n",
       "Training samples: 100          0.666667  \n",
       "Training samples: 150          0.677419  \n",
       "Training samples: 200          0.666667  \n",
       "Training samples: 250          0.711111  \n",
       "Training samples: 300          0.721805  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chosen Classifiers\n",
    "chosen_clfs = [DecisionTreeClassifier(criterion = \"entropy\"),\n",
    "        SVC(C = 1.0, kernel=\"rbf\"),\n",
    "        KNeighborsClassifier(n_neighbors = 3)]\n",
    "\n",
    "# Test Classifiers with increasing data set size\n",
    "training_sizes = [50,100,150,200,250,300]\n",
    "for clf in chosen_clfs:\n",
    "    print clf.__class__.__name__\n",
    "    table = makeTable(clf, training_sizes, X_train, X_test, y_train, y_test)\n",
    "    display(table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVC seemed the most stable across different training data set sizes. KNN had a strange u-shaped behavior, starting with a highish score decreasing, and then rising again. I decided to further explore them with grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choosing the Best Model\n",
    "\n",
    "- Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "- In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n",
    "- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n",
    "- What is the model's final F<sub>1</sub> score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Grid search time: 15.498 s\n",
      "Parameters of tuned model:  {'max_features': 'log2', 'min_samples_split': 3, 'max_depth': 2, 'min_samples_leaf': 8}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.802919708029 0.000 s\n",
      "------------------\n",
      "\n",
      "AdaBoostClassifier\n",
      "Grid search time: 10.084 s\n",
      "Parameters of tuned model:  {'n_estimators': 50, 'learning_rate': 0.6}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.779411764706 0.007 s\n",
      "------------------\n",
      "\n",
      "SVC\n",
      "Grid search time: 45.106 s\n",
      "Parameters of tuned model:  {'kernel': 'rbf', 'C': 150, 'gamma': 0.0001}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.786206896552 0.002 s\n",
      "------------------\n",
      "\n",
      "KNeighborsClassifier\n",
      "Grid search time: 2.923 s\n",
      "Parameters of tuned model:  {'n_neighbors': 30, 'weights': 'uniform', 'p': 2}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.77027027027 0.003 s\n",
      "------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fine-tune your model and report the best F1 score\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "r = np.arange\n",
    "scorer = make_scorer(F1)\n",
    "\n",
    "tree_param = { 'max_features':[\"sqrt\", \"log2\"], 'max_depth': range(2,11), 'min_samples_split':range(2,9),\n",
    "               'min_samples_leaf':range(1,9) }\n",
    "    \n",
    "svc_param  = [{'C':[100,150,200], 'kernel':['linear']}, \n",
    "              {'C':[100,150,200], 'gamma':[0.01, 0.001, 0.0001], 'kernel':['rbf']},\n",
    "              {'C':[100,150,200], 'degree':[2,3,4,5], 'coef0':[1,10,100],'kernel':['poly']}]\n",
    "\n",
    "neigh_param = {'n_neighbors' : [10,20,25,30,40], 'weights' : ['uniform', 'distance'], 'p':[1,2,3,5,10]}\n",
    "\n",
    "#Perform grid Search\n",
    "def gridIt(clf, params):\n",
    "    grid_clf = grid_search.GridSearchCV(clf, params, scorer)\n",
    "    print clf.__class__.__name__\n",
    "    print \"Grid search time:\", timeTraining(grid_clf, X_train, y_train)\n",
    "    print \"Parameters of tuned model: \", grid_clf.best_params_\n",
    "    y_pred, predict_t = predictAndTime(grid_clf, X_test)\n",
    "    print \"f1_score and prediction time on X_test, y_test: \"\n",
    "    print F1(y_test, y_pred), predict_t\n",
    "    print '------------------\\n'\n",
    "    \n",
    "gridIt(chosen_clfs[0], tree_param)\n",
    "gridIt(chosen_clfs[1], ada_param)\n",
    "gridIt(chosen_clfs[2], svc_param)\n",
    "gridIt(chosen_clfs[3], neigh_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Tree F1 for random state: 0 0.808176628012\n",
      "Average KNN F1 for random state: 0 0.787096774194\n",
      "------------------------------------\n",
      "Average Tree F1 for random state: 5 0.779762642075\n",
      "Average KNN F1 for random state: 5 0.786666666667\n",
      "------------------------------------\n",
      "Average Tree F1 for random state: 10 0.791981446416\n",
      "Average KNN F1 for random state: 10 0.810126582278\n",
      "------------------------------------\n",
      "Average Tree F1 for random state: 20 0.794643739379\n",
      "Average KNN F1 for random state: 20 0.802547770701\n",
      "------------------------------------\n",
      "Average Tree F1 for random state: 30 0.793069562794\n",
      "Average KNN F1 for random state: 30 0.782051282051\n",
      "------------------------------------\n",
      "Average Tree F1 for random state: 40 0.805694255864\n",
      "Average KNN F1 for random state: 40 0.815789473684\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##Confirm successfull DecisionTree and KNN parameters aquired from GridSearchCV\n",
    "\n",
    "dTree = DecisionTreeClassifier(max_features = 'log2', min_samples_split= 3, max_depth= 2, min_samples_leaf= 8)\n",
    "nn = KNeighborsClassifier(n_neighbors= 30, weights = 'uniform', p= 2)  \n",
    "\n",
    "rand_states = [0,5,10,20,30,40]\n",
    "\n",
    "def averageF1(clf, X_tr, y_tr, X_t):\n",
    "    sf1 = 0\n",
    "    for i in range(100):\n",
    "        clf.fit(X_tr,y_tr)\n",
    "        y_pred , p_time = predictAndTime(clf, X_t)\n",
    "        sf1 += F1(y_test, y_pred)\n",
    "        \n",
    "    return sf1/100\n",
    "    \n",
    "for s in rand_states:\n",
    "    X_tr, X_t, y_tr, y_t = train_test_split(X_all, y_all, \n",
    "                                                        test_size = .24, random_state = s)\n",
    "    print \"Average Tree F1 for random state: \" + str(s) + \" \" + str(averageF1(dTree, X_tr, y_tr, X_t))\n",
    "    print \"Average KNN F1 for random state: \"  + str(s) + \" \" + str(averageF1(nn, X_tr, y_tr, X_t))\n",
    "    print \"------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusions\n",
    "**Algorithm Selection:**  \n",
    "* * *\n",
    "My code reviewer pointed out that I had used the whole training set while I was still in model selection phase.\n",
    "After correcting this, the results from grid search in cell [100] became more comprehensible. Based on the computations performed there, although all algorithms (even if only marginally) benefited from the tuning process, two of them in my opinion are good candidates for consideration for final selection. These are DecisionTreeClassifier and KNeighborsClassifier. The SVM was very costly to tune with grid search, taking 45 seconds, with the next longest tuning being DecisionTree's at 15.5 seconds. Adaboost had a relatively fast training time of 10 s, but grid search failed to find a combination of parameters that significantly improved its final f1 score. For the the full training set size of 300, the DecisionTree had a marked f1 score improvement from 0.766 (cell [97]'s output) to 0.803. KNeighborsClassifier similarly benefitted from the grid search to improve its f1 score from 0.722 to 0.770. In previous attempts, when I found a good combination of parameters, performance seemed dependent on the particular run I had just observed. As hinted to me after the code review, the train/test spliting proccess can have marked effects on the algorithm's final performance, especially on small data sets like this one. To check that I had found consistently good parameters with grid search, I did a final test by averaging 100 f1_scores for each of 6 random_state seed values in train_test_split. As can be seen from the output of cell [115], both KNeighbors and DecisionTree sustained the good performance exhibited after grid search in cell [100], and also differed little from one another in f1_score. However KNeighbors grid_search training time was a mere 2.9 seconds. Therefore under the rubric of: available data, limited resources, cost, and performance, KNeighborsClassifier is the best model for use in this student intervention system. \n",
    "\n",
    "**Layman Explanation: KNeighborsClassifier**  \n",
    "* * *\n",
    "The mechanism with which our model decides whether a current student will pass or fail is very intuitive. Each student has 30 attributes associated with him/her. These range from basic descriptors like their age, sex, and health, to behavioral descriptors like whether they are in a romantic relationship, how much time they devote to study, if they have any extra curricular activities. Some of the attributes are of things out of there control like whether they have internet access, the size of their family, and what neighborhood they live in. What are model process does, is that it assigns a relevant number to every one of these attributes. Just like for example you can take a house and assign it a longitude, a latitude, and maybe if it sits on a hill an altitude. In the same way that information like longitude, latitude and altitude, alows us to decide how far away two houses are from each other, we can decide how \"far away\" two particular students are from each other. Based on all those attributes like free time and age and so forth. Since we have information about which students have failed and which have passed, our model basically answers the question; how \"close\" is this student to other students who have passed. Maybe he is \"closer\" to students who fail. We can choose to  compare him/her to the closest _single_ student to determine how likely he is to pass or fail. Usually, however we tune the model to find a _group_ of students closest to him/her, maybe the closest 4 students, or maybe 10 closest students. The exact number is determined while tuning. Since we use students that we know either passed or failed in this group, we can determine if our student in question is closer to others who pass or those who fail. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Final F1 score**\n",
    "* * *\n",
    "Given the way I selected the KNeighborsClassifier, I present the average and standard deviation of f1 scores across\n",
    "the different train/test splits of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average f1 score: 0.797379758263\n",
      "Std for the f1 scores 0.0128035136636\n"
     ]
    }
   ],
   "source": [
    "knn_f1_scores = [0.787096774194, 0.786666666667, 0.810126582278, 0.802547770701, 0.782051282051, 0.815789473684]\n",
    "print \"Average f1 score: {}\".format(np.mean(knn_f1_scores))\n",
    "print \"Std for the f1 scores {}\".format(np.std(knn_f1_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
