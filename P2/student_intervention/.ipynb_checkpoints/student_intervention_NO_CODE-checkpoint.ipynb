{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Project 2: Supervised Learning\n",
    "### Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification vs Regression\n",
    "\n",
    "Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?\n",
    "\n",
    "As we want to predict weather a given student will pass or fail, given information about his life and habits, this\n",
    "indicates a classification problem with two classes, pass and fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of students\n",
    "- Number of students who passed\n",
    "- Number of students who failed\n",
    "- Graduation rate of the class (%)\n",
    "- Number of features\n",
    "\n",
    "_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Let's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\n",
    "**Note**: For this dataset, the last column (`'passed'`) is the target or label we are trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Choose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\n",
    "\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "- Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.\n",
    "\n",
    "Produce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\n",
    "\n",
    "Note: You need to produce 3 such tables - one for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "**Model consideration**  \n",
    "\n",
    "Before we manipulated it, the data was strongly categorical. Even age, though ordered, basically could be thought of as buckets between 15 and 22. So initially I thought that maybe the DecisionTree would be the most apt to deal with this problem. Even though we saw in the lectures that decision trees handle continuous data as well, the motivation for the algorithm presented in class, made me think that it would handle this \"categorical\" data well (even though we made it numeric). Just as in class we had a boolean function with several weather related categories as input, and an output of play/no play tenis, so here we have data that is closely categorical, with a pass/no pass output. To get my bearings and not to impose any pre-judgement, I wanted to try most of the classifiers seen in class out of the box. I excluded neural net, since its recommended use requires the features to be scaled (one of the disadvantages of that algorithm). The result of this can be seen in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training time</th>\n",
       "      <td>0.010 s</td>\n",
       "      <td>0.023 s</td>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.158 s</td>\n",
       "      <td>0.001 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score training set</th>\n",
       "      <td>1</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.868778</td>\n",
       "      <td>0.886878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction time</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.005 s</td>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.007 s</td>\n",
       "      <td>0.003 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 score test set</th>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.721805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DecisionTreeClassifier       SVC GaussianNB  \\\n",
       "Training time                        0.010 s   0.023 s    0.002 s   \n",
       "F1 score training set                      1  0.869198   0.808824   \n",
       "Prediction time                      0.001 s   0.005 s    0.001 s   \n",
       "F1 score test set                   0.755906  0.758621       0.75   \n",
       "\n",
       "                      AdaBoostClassifier KNeighborsClassifier  \n",
       "Training time                    0.158 s              0.001 s  \n",
       "F1 score training set           0.868778             0.886878  \n",
       "Prediction time                  0.007 s              0.003 s  \n",
       "F1 score test set               0.779412             0.721805  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After this preliminary experiment, I don't feel I can say any algorithm is particularly suited or ill-suited here. All of them out of the box pretty much give very similar f1_scores on the test set after training. I decided to further explore them with grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>F1 score training set</th>\n",
       "      <th>Prediction time</th>\n",
       "      <th>F1 score test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training samples: 50</th>\n",
       "      <td>0.002 s</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.80597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 100</th>\n",
       "      <td>0.003 s</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.725806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 150</th>\n",
       "      <td>0.004 s</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 200</th>\n",
       "      <td>0.004 s</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.71875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 250</th>\n",
       "      <td>0.005 s</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.710744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 300</th>\n",
       "      <td>0.005 s</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\n",
       "Training samples: 50        0.002 s                     1         0.001 s   \n",
       "Training samples: 100       0.003 s                     1         0.000 s   \n",
       "Training samples: 150       0.004 s                     1         0.000 s   \n",
       "Training samples: 200       0.004 s                     1         0.000 s   \n",
       "Training samples: 250       0.005 s                     1         0.000 s   \n",
       "Training samples: 300       0.005 s                     1         0.000 s   \n",
       "\n",
       "                      F1 score test set  \n",
       "Training samples: 50            0.80597  \n",
       "Training samples: 100          0.725806  \n",
       "Training samples: 150          0.697674  \n",
       "Training samples: 200           0.71875  \n",
       "Training samples: 250          0.710744  \n",
       "Training samples: 300          0.765625  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>F1 score training set</th>\n",
       "      <th>Prediction time</th>\n",
       "      <th>F1 score test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training samples: 50</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.738462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 100</th>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.85906</td>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 150</th>\n",
       "      <td>0.003 s</td>\n",
       "      <td>0.870813</td>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 200</th>\n",
       "      <td>0.004 s</td>\n",
       "      <td>0.869281</td>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.77551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 250</th>\n",
       "      <td>0.006 s</td>\n",
       "      <td>0.879177</td>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 300</th>\n",
       "      <td>0.008 s</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\n",
       "Training samples: 50        0.001 s               0.90625         0.001 s   \n",
       "Training samples: 100       0.002 s               0.85906         0.001 s   \n",
       "Training samples: 150       0.003 s              0.870813         0.002 s   \n",
       "Training samples: 200       0.004 s              0.869281         0.002 s   \n",
       "Training samples: 250       0.006 s              0.879177         0.002 s   \n",
       "Training samples: 300       0.008 s              0.869198         0.002 s   \n",
       "\n",
       "                      F1 score test set  \n",
       "Training samples: 50           0.738462  \n",
       "Training samples: 100          0.783784  \n",
       "Training samples: 150          0.771429  \n",
       "Training samples: 200           0.77551  \n",
       "Training samples: 250          0.758621  \n",
       "Training samples: 300          0.758621  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>F1 score training set</th>\n",
       "      <th>Prediction time</th>\n",
       "      <th>F1 score test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training samples: 50</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.468085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 100</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.748092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 150</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.808743</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 200</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.713178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 250</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.817647</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 300</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.000 s</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\n",
       "Training samples: 50        0.001 s              0.666667         0.000 s   \n",
       "Training samples: 100       0.001 s              0.854962         0.000 s   \n",
       "Training samples: 150       0.001 s              0.808743         0.000 s   \n",
       "Training samples: 200       0.001 s              0.832061         0.000 s   \n",
       "Training samples: 250       0.001 s              0.817647         0.000 s   \n",
       "Training samples: 300       0.001 s              0.808824         0.000 s   \n",
       "\n",
       "                      F1 score test set  \n",
       "Training samples: 50           0.468085  \n",
       "Training samples: 100          0.748092  \n",
       "Training samples: 150          0.736842  \n",
       "Training samples: 200          0.713178  \n",
       "Training samples: 250          0.746269  \n",
       "Training samples: 300              0.75  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>F1 score training set</th>\n",
       "      <th>Prediction time</th>\n",
       "      <th>F1 score test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training samples: 50</th>\n",
       "      <td>0.104 s</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006 s</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 100</th>\n",
       "      <td>0.095 s</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.006 s</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 150</th>\n",
       "      <td>0.098 s</td>\n",
       "      <td>0.912821</td>\n",
       "      <td>0.006 s</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 200</th>\n",
       "      <td>0.100 s</td>\n",
       "      <td>0.882562</td>\n",
       "      <td>0.006 s</td>\n",
       "      <td>0.805755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 250</th>\n",
       "      <td>0.102 s</td>\n",
       "      <td>0.886427</td>\n",
       "      <td>0.006 s</td>\n",
       "      <td>0.776978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 300</th>\n",
       "      <td>0.105 s</td>\n",
       "      <td>0.868778</td>\n",
       "      <td>0.006 s</td>\n",
       "      <td>0.779412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\n",
       "Training samples: 50        0.104 s                     1         0.006 s   \n",
       "Training samples: 100       0.095 s              0.953846         0.006 s   \n",
       "Training samples: 150       0.098 s              0.912821         0.006 s   \n",
       "Training samples: 200       0.100 s              0.882562         0.006 s   \n",
       "Training samples: 250       0.102 s              0.886427         0.006 s   \n",
       "Training samples: 300       0.105 s              0.868778         0.006 s   \n",
       "\n",
       "                      F1 score test set  \n",
       "Training samples: 50           0.645161  \n",
       "Training samples: 100              0.72  \n",
       "Training samples: 150          0.757576  \n",
       "Training samples: 200          0.805755  \n",
       "Training samples: 250          0.776978  \n",
       "Training samples: 300          0.779412  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>F1 score training set</th>\n",
       "      <th>Prediction time</th>\n",
       "      <th>F1 score test set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training samples: 50</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 100</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 150</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.003 s</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 200</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.86121</td>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 250</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.889503</td>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.711111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training samples: 300</th>\n",
       "      <td>0.001 s</td>\n",
       "      <td>0.886878</td>\n",
       "      <td>0.002 s</td>\n",
       "      <td>0.721805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Training time F1 score training set Prediction time  \\\n",
       "Training samples: 50        0.001 s                   0.8         0.002 s   \n",
       "Training samples: 100       0.001 s              0.823529         0.002 s   \n",
       "Training samples: 150       0.001 s              0.816327         0.003 s   \n",
       "Training samples: 200       0.001 s               0.86121         0.002 s   \n",
       "Training samples: 250       0.001 s              0.889503         0.002 s   \n",
       "Training samples: 300       0.001 s              0.886878         0.002 s   \n",
       "\n",
       "                      F1 score test set  \n",
       "Training samples: 50           0.761905  \n",
       "Training samples: 100          0.666667  \n",
       "Training samples: 150          0.677419  \n",
       "Training samples: 200          0.666667  \n",
       "Training samples: 250          0.711111  \n",
       "Training samples: 300          0.721805  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were relatively stable as training size increased. The SVC seemed the most stable acrosss different \n",
    "training data set sizes. KNN had a strange u-shaped behavior, starting with a \n",
    "highish score decreasing, and then rising again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choosing the Best Model\n",
    "\n",
    "- Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?\n",
    "- In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).\n",
    "- Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.\n",
    "- What is the model's final F<sub>1</sub> score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "Grid search time: 15.498 s\n",
      "Parameters of tuned model:  {'max_features': 'log2', 'min_samples_split': 3, 'max_depth': 2, 'min_samples_leaf': 8}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.802919708029 0.000 s\n",
      "------------------\n",
      "\n",
      "AdaBoostClassifier\n",
      "Grid search time: 10.084 s\n",
      "Parameters of tuned model:  {'n_estimators': 50, 'learning_rate': 0.6}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.779411764706 0.007 s\n",
      "------------------\n",
      "\n",
      "SVC\n",
      "Grid search time: 45.106 s\n",
      "Parameters of tuned model:  {'kernel': 'rbf', 'C': 150, 'gamma': 0.0001}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.786206896552 0.002 s\n",
      "------------------\n",
      "\n",
      "KNeighborsClassifier\n",
      "Grid search time: 2.923 s\n",
      "Parameters of tuned model:  {'n_neighbors': 30, 'weights': 'uniform', 'p': 2}\n",
      "f1_score and prediction time on X_test, y_test: \n",
      "0.77027027027 0.003 s\n",
      "------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Tree F1 for random state: 0 0.808176628012\n",
      "Average KNN F1 for random state: 0 0.787096774194\n",
      "------------------------------------\n",
      "Average Tree F1 for random state: 5 0.779762642075\n",
      "Average KNN F1 for random state: 5 0.786666666667\n",
      "------------------------------------\n",
      "Average Tree F1 for random state: 10 0.791981446416\n",
      "Average KNN F1 for random state: 10 0.810126582278\n",
      "------------------------------------\n",
      "Average Tree F1 for random state: 20 0.794643739379\n",
      "Average KNN F1 for random state: 20 0.802547770701\n",
      "------------------------------------\n",
      "Average Tree F1 for random state: 30 0.793069562794\n",
      "Average KNN F1 for random state: 30 0.782051282051\n",
      "------------------------------------\n",
      "Average Tree F1 for random state: 40 0.805694255864\n",
      "Average KNN F1 for random state: 40 0.815789473684\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusions\n",
    "**Algorithm Selection:**  \n",
    "* * *\n",
    "My code reviewer pointed out that I had used the whole training set while I was still in model selection phase.\n",
    "After correcting this, the results from grid search in cell [100] became more comprehensible. Based on the computations performed there, although all algorithms (even if only marginally) benefited from the tuning process, two of them in my opinion are good candidates for consideration for final selection. These are DecisionTreeClassifier and KNeighborsClassifier. The SVM was very costly to tune with grid search, taking 45 seconds, with the next longest tuning being DecisionTree's at 15.5 seconds. Adaboost had a relatively fast training time of 10 s, but grid search failed to find a combination of parameters that significantly improved its final f1 score. For the the full training set size of 300, the DecisionTree had a marked f1 score improvement from 0.766 (cell [97]'s output) to 0.803. KNeighborsClassifier similarly benefitted from the grid search to improve its f1 score from 0.722 to 0.770. In previous attempts, when I found a good combination of parameters, performance seemed dependent on the particular run I had just observed. As hinted to me after the code review, the train/test spliting proccess can have marked effects on the algorithm's final performance, especially on small data sets like this one. To check that I had found consistently good parameters with grid search, I did a final test by averaging 100 f1_scores for each of 6 random_state seed values in train_test_split. As can be seen from the output of cell [115], both KNeighbors and DecisionTree sustained the good performance exhibited after grid search in cell [100], and also differed little from one another in f1_score. However KNeighbors grid_search training time was a mere 2.9 seconds. Therefore under the rubric of: available data, limited resources, cost, and performance, KNeighborsClassifier is the best model for use in this student intervention system. \n",
    "\n",
    "**Layman Explanation: KNeighborsClassifier**  \n",
    "* * *\n",
    "The mechanism with which our model decides whether a current student will pass or fail is very intuitive. Each student has 30 attributes associated with him/her. These range from basic descriptors like their age, sex, and health, to behavioral descriptors like whether they are in a romantic relationship, how much time they devote to study, if they have any extra curricular activities. Some of the attributes are of things out of there control like whether they have internet access, the size of their family, and what neighborhood they live in. What are model process does, is that it assigns a relevant number to every one of these attributes. Just like for example you can take a house and assign it a longitude, a latitude, and maybe if it sits on a hill an altitude. In the same way that information like longitude, latitude and altitude, alows us to decide how far away two houses are from each other, we can decide how \"far away\" two particular students are from each other. Based on all those attributes like free time and age and so forth. Since we have information about which students have failed and which have passed, our model basically answers the question; how \"close\" is this student to other students who have passed. Maybe he is \"closer\" to students who fail. We can choose to  compare him/her to the closest _single_ student to determine how likely he is to pass or fail. Usually, however we tune the model to find a _group_ of students closest to him/her, maybe the closest 4 students, or maybe 10 closest students. The exact number is determined while tuning. Since we use students that we know either passed or failed in this group, we can determine if our student in question is closer to others who pass or those who fail. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Final F1 score**\n",
    "* * *\n",
    "Given the way I selected the KNeighborsClassifier, I present the average and standard deviation of f1 scores across\n",
    "the different train/test splits of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average f1 score: 0.797379758263\n",
      "Std for the f1 scores 0.0128035136636\n"
     ]
    }
   ],
   "source": [
    "knn_f1_scores = [0.787096774194, 0.786666666667, 0.810126582278, 0.802547770701, 0.782051282051, 0.815789473684]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
